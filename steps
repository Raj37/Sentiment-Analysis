										Sentiment Analysis using Stanford NLP
step 1: Create source hive table i.e. source_tbl
create table source_tbl(id int,A string,B string,C string,D string,E string,F string,G string,H string,I string,J string,K string,L string,M string,N string,O string,P string,Q string,R string,S string,T string,U string,V string,W string,X string,Y string,Z string,AA string,AB string,AC string,AD string,AE string,AF string,AG string,AH string,AI string,AJ string,AK string,AL string,AM string,AN string,AO string,AP string,AQ string,AR string,AS1 string,AT string,AU string,AV string,AW string,AX string,AY string,AZ string,BA string,BB string,BC string,BD string,BE string,BF string,BG string,BH string,BI string,BJ string,BK string,BL string,BM string,BN string,BO string,BP string,BQ string,BR string,BS string,BT string,BU string,BV string,BW string,BX string,BY1 string,BZ string,CA string,CB string,CC string,CD string,CE string,CF string,CG string)row format delimited fields terminated by '|' lines terminated by '\n';     -86 columns

step 2: Load data into hive table
load data local inpath '/home/cloudera/Desktop/kafka/DR/source' overwrite into table source_tbl;

step 3: Create temporary hive table for M column of source table
create table M_TMP(m_col string)row format delimited lines terminated by '\n';

step 4: Insert M column data from source table into temp table i.e. M_TMP
insert into M_TMP select m from source_tbl;

step 5: hdfs path for table M_TMP
hdfs://quickstart.cloudera:8020/user/hive/warehouse/sentiment.db/m_tmp

step 6: Copy hive table i.e. M_TMP data to local
hadoop fs -copyToLocal hdfs://quickstart.cloudera:8020/user/hive/warehouse/sentiment.db/m_tmp/000000_0 /home/cloudera/Desktop/kafka/DR/comment

step 7: Rename the input file
mv /home/cloudera/Desktop/kafka/DR/comment/000000_0 /home/cloudera/Desktop/kafka/DR/comment/input1	

step 8: Execute java code for sentiment analysis and generate output with sentiment for clients comments

step 9: Create M_TBL with sentiment column
create table M_TBL(id int,m_col string,m_sentiment string)row format delimited fields terminated by '|' lines terminated by '\n';

step 10: Load data into M_TBL
load data local inpath '/home/cloudera/Desktop/kafka/DR/comment/output1' overwrite into table M_TBL;

step 11: Create temporary hive table for N column of source table
create table N_TMP(n_col string)row format delimited lines terminated by '\n';

step 12: Insert N column data from source table into temp table i.e. N_TMP 
insert into N_TMP select n from source_tbl;-done

step 13: hdfs path for table N_TMP 
hdfs://quickstart.cloudera:8020/user/hive/warehouse/sentiment.db/n_tmp

step 14: Copy hive table i.e. N_TMP data to local
hadoop fs -copyToLocal hdfs://quickstart.cloudera:8020/user/hive/warehouse/sentiment.db/n_tmp/000000_0 /home/cloudera/Desktop/kafka/DR/comment

step 15: Rename the input file
mv /home/cloudera/Desktop/kafka/DR/comment/000000_0 /home/cloudera/Desktop/kafka/DR/comment/input2	

step 16: Execute java code for sentiment analysis and generate output with sentiment for clients comments 

step 17: Create N_TBL with sentiment column 
create table N_TBL(id int,n_col string,n_sentiment string)row format delimited fields terminated by '|' lines terminated by '\n';

step 18: Load data into N_TBL
load data local inpath '/home/cloudera/Desktop/kafka/DR/comment/output2' overwrite into table N_TBL;

step 19: Create temporary hive table for W column of source table
create table W_TMP(w_col string)row format delimited lines terminated by '\n';

step 20: Insert W column data from source table into temp table i.e. W_TMP
insert into W_TMP select w from source_tbl;

step 21: hdfs path for table W_TMP  
hdfs://quickstart.cloudera:8020/user/hive/warehouse/sentiment.db/w_tmp

step 22: Copy hive table i.e. W_TMP data to local
hadoop fs -copyToLocal hdfs://quickstart.cloudera:8020/user/hive/warehouse/sentiment.db/w_tmp/000000_0 /home/cloudera/Desktop/kafka/DR/comment

step 23: Rename the input file
mv /home/cloudera/Desktop/kafka/DR/comment/000000_0 /home/cloudera/Desktop/kafka/DR/comment/input3	

step 24: Execute java code for sentiment analysis and generate output with sentiment for clients comments

step 25: Create W_TBL with sentiment column
create table W_TBL(id int,w_col string,w_sentiment string)row format delimited fields terminated by '|' lines terminated by '\n';

step 26: Load data into W_TBL
load data local inpath '/home/cloudera/Desktop/kafka/DR/comment/output3' overwrite into table W_TBL;

step 27: Create temporary hive table for AU column of source table
create table AU_TMP(au_col string)row format delimited lines terminated by '\n';

step 28: Insert AU column data from source table into temp table i.e. AU_TMP
insert into AU_TMP select au from source_tbl; 

step 29: hdfs path for table W_TMP  
hdfs://quickstart.cloudera:8020/user/hive/warehouse/sentiment.db/au_tmp -done

step 30: Copy hive table i.e. AU_TMP data to local
hadoop fs -copyToLocal hdfs://quickstart.cloudera:8020/user/hive/warehouse/sentiment.db/au_tmp/000000_0 /home/cloudera/Desktop/kafka/DR/comment

step 31: Rename the input file
mv /home/cloudera/Desktop/kafka/DR/comment/000000_0 /home/cloudera/Desktop/kafka/DR/comment/input4	

step 32: Execute java code for sentiment analysis and generate output with sentiment for clients comments 

step 33: Create AU_TBL with sentiment column
create table AU_TBL(id int,au_col string,au_sentiment string)row format delimited fields terminated by '|' lines terminated by '\n';

step 34: Load data into AU_TBL
load data local inpath '/home/cloudera/Desktop/kafka/DR/comment/output4' overwrite into table AU_TBL;

step 35: Create final hive table i.e. final_tbl

create table final_tbl(id int,A int,B string,C string,D string,E string,F string,G string,H string,I string,J string,K string,L string,M string,M_SENTIMENT string,N string,N_SENTIMENT string,O string,P string,Q string,R string,S string,T string,U string,V string,W string,W_SENTIMENT string,X string,Y string,Z string,AA string,AB string,AC string,AD string,AE string,AF string,AG string,AH string,AI string,AJ string,AK string,AL string,AM string,AN string,AO string,AP string,AQ string,AR string,AS string,AT string,AU string,AU_SENTIMENT string,AV string,AW string,AX string,AY string,AZ string,BA string,BB string,BC string,BD string,BE string,BF string,BG string,BH string,BI string,BJ string,BK string,BL string,BM string,BN string,BO string,BP string,BQ string,BR string,BS string,BT string,BU string,BV string,BW string,BX string,BY string,BZ string,CA string,CB string,CC string,CD string,CE string,CF string,CG string)row format delimited fields terminated by '|' lines terminated by '\n'; -90 columns

step 36: Joining 5 tables i.e. source_tbl, M_TBL, N_TBL, W_TBL and AU_TBL and insert into final_tbl

insert into final_tbl select a1.id,a1.A,a1.B,a1.C,a1.D,a1.E,a1.F,a1.G,a1.H,a1.I,a1.J,a1.K,a1.L,a1.M,b1.M_SENTIMENT,a1.N,c1.N_SENTIMENT,a1.O,a1.P,a1.Q,a1.R,a1.S,a1.T,a1.U,a1.V,a1.W,d1.W_SENTIMENT,a1.X,a1.Y,a1.Z,
a1.AA,a1.AB,a1.AC,a1.AD,a1.AE,a1.AF,a1.AG,a1.AH,a1.AI,a1.AJ,a1.AK,a1.AL,a1.AM,a1.AN,a1.AO,a1.AP,a1.AQ,a1.AR,a1.AS,a1.AT,a1.AU,e1.AU_SENTIMENT,a1.AV,a1.AW,a1.AX,a1.AY,a1.AZ,
a1.BA,a1.BB,a1.BC,a1.BD,a1.BE,a1.BF,a1.BG,a1.BH,a1.BI,a1.BJ,a1.BK,a1.BL,a1.BM,a1.BN,a1.BO,a1.BP,a1.BQ,a1.BR,a1.BS,a1.BT,a1.BU,a1.BV,a1.BW,a1.BX,a1.BY,a1.BZ,
a1.CA,a1.CB,a1.CC,a1.CD,a1.CE,a1.CF,a1.CG from source_tbl as a1 left outer join M_TBL as b1 on (a1.id=b1.id) left outer join N_TBL as c1 on (a1.id=c1.id) left outer join W_TBL as d1 on (a1.id=d1.id) left outer join AU_TBL as e1 on (a1.id=e1.id);

step 37: Copy hive table i.e. final_tbl data to local
hadoop fs -copyToLocal hdfs://quickstart.cloudera:8020/user/hive/warehouse/sentiment.db/final_tbl/000000_0 /home/cloudera/Desktop/kafka/DR/output

step 38: Rename the output file
mv /home/cloudera/Desktop/kafka/DR/output/000000_0 /home/cloudera/Desktop/kafka/DR/output/final

step 39: Run unix shell script i.e. MainScript.sh for generating file i.e final with their sentiment as a result
./MainScript.sh



